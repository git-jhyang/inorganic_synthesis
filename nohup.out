multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/jhyang/anaconda3/envs/isyn2/lib/python3.9/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/jhyang/anaconda3/envs/isyn2/lib/python3.9/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/mnt/CODES/inorganic_synthesis/execute.py", line 32, in exc
    R.main(R.args)
  File "/mnt/CODES/inorganic_synthesis/run_gcvae.py", line 111, in main
    writer.add_histogram(f'Z/{sfx}', output['z'], epoch)
  File "/home/jhyang/anaconda3/envs/isyn2/lib/python3.9/site-packages/torch/utils/tensorboard/writer.py", line 526, in add_histogram
    histogram(tag, values, bins, max_bins=max_bins), global_step, walltime
  File "/home/jhyang/anaconda3/envs/isyn2/lib/python3.9/site-packages/torch/utils/tensorboard/summary.py", line 483, in histogram
    hist = make_histogram(values.astype(float), bins, max_bins)
  File "/home/jhyang/anaconda3/envs/isyn2/lib/python3.9/site-packages/torch/utils/tensorboard/summary.py", line 528, in make_histogram
    raise ValueError("The histogram is empty, please file a bug report.")
ValueError: The histogram is empty, please file a bug report.
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/CODES/inorganic_synthesis/execute.py", line 35, in <module>
    pool.map(exc, [i for i in range(600)])
  File "/home/jhyang/anaconda3/envs/isyn2/lib/python3.9/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/jhyang/anaconda3/envs/isyn2/lib/python3.9/multiprocessing/pool.py", line 771, in get
    raise self._value
ValueError: The histogram is empty, please file a bug report.
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/jhyang/anaconda3/envs/isyn2/lib/python3.9/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/jhyang/anaconda3/envs/isyn2/lib/python3.9/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/jhyang/WORKSPACES/CODES/inorganic_synthesis/execute.py", line 32, in exc
    R.main(R.args)
  File "/home/jhyang/WORKSPACES/CODES/inorganic_synthesis/run_gcvae_class.py", line 112, in main
    writer.add_histogram(f'Z/{sfx}', output['z'], epoch)
  File "/home/jhyang/anaconda3/envs/isyn2/lib/python3.9/site-packages/torch/utils/tensorboard/writer.py", line 526, in add_histogram
    histogram(tag, values, bins, max_bins=max_bins), global_step, walltime
  File "/home/jhyang/anaconda3/envs/isyn2/lib/python3.9/site-packages/torch/utils/tensorboard/summary.py", line 483, in histogram
    hist = make_histogram(values.astype(float), bins, max_bins)
  File "/home/jhyang/anaconda3/envs/isyn2/lib/python3.9/site-packages/torch/utils/tensorboard/summary.py", line 528, in make_histogram
    raise ValueError("The histogram is empty, please file a bug report.")
ValueError: The histogram is empty, please file a bug report.
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/jhyang/WORKSPACES/CODES/inorganic_synthesis/execute.py", line 35, in <module>
    pool.map(exc, [i for i in range(600)])
  File "/home/jhyang/anaconda3/envs/isyn2/lib/python3.9/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/jhyang/anaconda3/envs/isyn2/lib/python3.9/multiprocessing/pool.py", line 771, in get
    raise self._value
ValueError: The histogram is empty, please file a bug report.
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/jhyang/anaconda3/envs/isyn2/lib/python3.9/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/jhyang/anaconda3/envs/isyn2/lib/python3.9/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/jhyang/WORKSPACES/CODES/inorganic_synthesis/execute_tf.py", line 20, in exc
    R.main(R.args)
  File "/home/jhyang/WORKSPACES/CODES/inorganic_synthesis/run_transf.py", line 87, in main
    train_loss = trainer.train(train_dl)
  File "/home/jhyang/WORKSPACES/CODES/inorganic_synthesis/src/trainer.py", line 15, in train
    for batch in dataloader:
  File "/home/jhyang/anaconda3/envs/isyn2/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 439, in __iter__
    return self._get_iterator()
  File "/home/jhyang/anaconda3/envs/isyn2/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 387, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/jhyang/anaconda3/envs/isyn2/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1040, in __init__
    w.start()
  File "/home/jhyang/anaconda3/envs/isyn2/lib/python3.9/multiprocessing/process.py", line 118, in start
    assert not _current_process._config.get('daemon'), \
AssertionError: daemonic processes are not allowed to have children
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/jhyang/WORKSPACES/CODES/inorganic_synthesis/execute_tf.py", line 23, in <module>
    pool.map(exc, [i for i in range(600)])
  File "/home/jhyang/anaconda3/envs/isyn2/lib/python3.9/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/jhyang/anaconda3/envs/isyn2/lib/python3.9/multiprocessing/pool.py", line 771, in get
    raise self._value
AssertionError: daemonic processes are not allowed to have children
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/jhyang/anaconda3/envs/isyn2/lib/python3.9/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/jhyang/anaconda3/envs/isyn2/lib/python3.9/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/jhyang/WORKSPACES/CODES/inorganic_synthesis/execute_tf.py", line 20, in exc
    R.main(R.args)
  File "/home/jhyang/WORKSPACES/CODES/inorganic_synthesis/run_transf.py", line 72, in main
    model = TransformerDecoderBlock(context_dim = DS.num_condition_feat,
  File "/home/jhyang/WORKSPACES/CODES/inorganic_synthesis/src/networks.py", line 290, in __init__
    torch.nn.TransformerDecoderLayer(
  File "/home/jhyang/anaconda3/envs/isyn2/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 780, in __init__
    self.self_attn = MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=batch_first,
  File "/home/jhyang/anaconda3/envs/isyn2/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 991, in __init__
    assert self.head_dim * num_heads == self.embed_dim, "embed_dim must be divisible by num_heads"
AssertionError: embed_dim must be divisible by num_heads
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/jhyang/WORKSPACES/CODES/inorganic_synthesis/execute_tf.py", line 23, in <module>
    pool.map(exc, [i for i in range(600)])
  File "/home/jhyang/anaconda3/envs/isyn2/lib/python3.9/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/jhyang/anaconda3/envs/isyn2/lib/python3.9/multiprocessing/pool.py", line 771, in get
    raise self._value
AssertionError: embed_dim must be divisible by num_heads
python: can't open file '/home/jhyang/WORKSPACES/CODES/inorganic_synthesis/execute_tf.py': [Errno 2] No such file or directory
Traceback (most recent call last):
  File "/home/jhyang/WORKSPACES/CODES/inorganic_synthesis/execute_urxn.py", line 2, in <module>
    import seq_urxn as R
  File "/home/jhyang/WORKSPACES/CODES/inorganic_synthesis/seq_urxn.py", line 6, in <module>
    from src.networks import TransformerDecoderBlock
ImportError: cannot import name 'TransformerDecoderBlock' from 'src.networks' (/home/jhyang/WORKSPACES/CODES/inorganic_synthesis/src/networks.py)
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/jhyang/anaconda3/envs/isyn2/lib/python3.9/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/jhyang/anaconda3/envs/isyn2/lib/python3.9/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/jhyang/WORKSPACES/CODES/inorganic_synthesis/execute_urxn.py", line 20, in exc
    R.main(R.args)
  File "/home/jhyang/WORKSPACES/CODES/inorganic_synthesis/seq_urxn.py", line 59, in main
    DS = ReactionDataset(feat_type = args.feature_type,
  File "/home/jhyang/WORKSPACES/CODES/inorganic_synthesis/src/data.py", line 363, in __init__
    self.precursor_dataset = PrecursorDataset(feat_type=feat_type,
  File "/home/jhyang/WORKSPACES/CODES/inorganic_synthesis/src/feature.py", line 142, in __init__
    with gzip.open(path, 'rb') as f:
  File "/home/jhyang/anaconda3/envs/isyn2/lib/python3.9/gzip.py", line 58, in open
    binary_file = GzipFile(filename, gz_mode, compresslevel)
  File "/home/jhyang/anaconda3/envs/isyn2/lib/python3.9/gzip.py", line 173, in __init__
    fileobj = self.myfileobj = builtins.open(filename, mode or 'rb')
FileNotFoundError: [Errno 2] No such file or directory: '../data/screened_precursor.pkl.gz'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/jhyang/WORKSPACES/CODES/inorganic_synthesis/execute_urxn.py", line 23, in <module>
    pool.map(exc, [i for i in range(300)])
  File "/home/jhyang/anaconda3/envs/isyn2/lib/python3.9/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/jhyang/anaconda3/envs/isyn2/lib/python3.9/multiprocessing/pool.py", line 771, in get
    raise self._value
FileNotFoundError: [Errno 2] No such file or directory: '../data/screened_precursor.pkl.gz'
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/jhyang/anaconda3/envs/isyn2/lib/python3.9/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/jhyang/anaconda3/envs/isyn2/lib/python3.9/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/jhyang/WORKSPACES/CODES/inorganic_synthesis/execute_urxn.py", line 20, in exc
    R.main(R.args)
  File "/home/jhyang/WORKSPACES/CODES/inorganic_synthesis/seq_urxn.py", line 77, in main
    model = TransformerDecoderBlock(context_dim = DS.num_condition_feat,
TypeError: __init__() missing 2 required positional arguments: 'feature_dim' and 'vocab_dim'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/jhyang/WORKSPACES/CODES/inorganic_synthesis/execute_urxn.py", line 23, in <module>
    pool.map(exc, [i for i in range(300)])
  File "/home/jhyang/anaconda3/envs/isyn2/lib/python3.9/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/jhyang/anaconda3/envs/isyn2/lib/python3.9/multiprocessing/pool.py", line 771, in get
    raise self._value
TypeError: __init__() missing 2 required positional arguments: 'feature_dim' and 'vocab_dim'
