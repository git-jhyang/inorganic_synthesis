{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, gzip, pickle\n",
    "sys.path.append('..')\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from src.networks import DNNBlock, BaseNetwork\n",
    "from src.data import feature_to_composition, BaseDataset, CompositionData\n",
    "from src.trainer import DefaultTrainer\n",
    "\n",
    "class AutoEncoder(BaseNetwork):\n",
    "    def __init__(self,\n",
    "                 input_dim:int, \n",
    "                 latent_dim:int, \n",
    "                 encoder_hidden_dim:int = 32,\n",
    "                 encoder_hidden_layers:int = 2,\n",
    "                 decoder_hidden_dim:int = 32,\n",
    "                 decoder_hidden_layers:int = 2,\n",
    "                 batch_norm:bool = True, \n",
    "                 dropout:float = 0,\n",
    "                 activation:str = 'LeakyReLU',\n",
    "                 **kwargs): \n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self._model_param = {\n",
    "            'input_dim':input_dim,\n",
    "            'latent_dim':latent_dim,\n",
    "            'encoder_hidden_dim':encoder_hidden_dim,\n",
    "            'encoder_hidden_layers':encoder_hidden_layers,\n",
    "            'decoder_hidden_dim':decoder_hidden_dim,\n",
    "            'decoder_hidden_layers':decoder_hidden_layers,\n",
    "            'batch_norm':batch_norm,\n",
    "            'dropout':dropout,\n",
    "            'activation':activation,\n",
    "        }\n",
    "        self.comp_encoder = DNNBlock(input_dim, latent_dim, encoder_hidden_dim, \n",
    "                                     encoder_hidden_layers, batch_norm, dropout, activation)\n",
    "        self.comp_decoder = DNNBlock(latent_dim, input_dim, decoder_hidden_dim, \n",
    "                                     decoder_hidden_layers, batch_norm, dropout, activation)\n",
    "\n",
    "    def forward(self, x):\n",
    "        l = self.comp_encoder(x)\n",
    "        y = torch.nn.Sigmoid()(self.comp_decoder(l))\n",
    "        return l, y\n",
    "\n",
    "    def save(self, path, prefix, overwrite=True):\n",
    "        self._save(path, f'{prefix}_full.model', overwrite)\n",
    "        self.comp_encoder._save(path, f'{prefix}_encoder.model', overwrite)\n",
    "        self.comp_decoder._save(path, f'{prefix}_decoder.model', overwrite)\n",
    "\n",
    "\n",
    "def cfn(dataset):\n",
    "    feat = []\n",
    "    info = []\n",
    "    for data in dataset:\n",
    "        feat.append(data.comp_feat)\n",
    "        info.append(data.to_dict())\n",
    "    return torch.vstack(feat), info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24120, 1988, 2485)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import time, pickle\n",
    "\n",
    "DS = CompositionDataset()\n",
    "DS.from_file()\n",
    "DS.to('cuda')\n",
    "\n",
    "target_test_mask = DS._year > 2018\n",
    "target_valid_mask = DS._year == 2018\n",
    "target_train_mask = DS._year < 2018\n",
    "\n",
    "train_dl = DataLoader(DS, batch_size=128, \n",
    "                      sampler=SubsetRandomSampler(np.where(target_train_mask)[0]))\n",
    "valid_dl = DataLoader(DS, batch_size=4096, \n",
    "                      sampler=np.where(target_valid_mask)[0])\n",
    "test_dl = DataLoader(DS, batch_size=4096, \n",
    "                     sampler=np.where(target_test_mask)[0])\n",
    "\n",
    "target_train_mask.sum(), target_valid_mask.sum(), target_test_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.47668373, 0.2887895 , 0.00311273, 0.00206484]),\n",
       " array([7.31276733e-02, 3.24810087e-02, 1.13259765e-03, 5.64105847e-05]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "model = AutoEncoder(104, 16, encoder_hidden_dim=64, encoder_hidden_layers=4, \n",
    "                    decoder_hidden_dim=64, decoder_hidden_layers=4)\n",
    "#model_c = torch.compile(model)\n",
    "#trainer = AETrainer(model_c, 1e-4, device='cuda')\n",
    "trainer = AETrainer(model, 1e-4, device='cuda')\n",
    "\n",
    "ts = []\n",
    "for i in range(50):\n",
    "    t0 = time.time()\n",
    "    trainer.train(train_dl)\n",
    "    t1 = time.time()\n",
    "    trainer.test(train_dl)\n",
    "    t2 = time.time()\n",
    "    trainer.test(valid_dl)\n",
    "    t3 = time.time()\n",
    "    trainer.test(test_dl)\n",
    "    t4 = time.time()\n",
    "    ts.append([t1-t0, t2-t1, t3-t2, t4-t3])\n",
    "np.mean(ts, 0), np.std(ts, 0)\n",
    "\n",
    "with open('../dump/time_torch_v2c.pkl','wb') as f:\n",
    "    pickle.dump(np.array(ts), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9595169, 3.4811459)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, out = trainer.test(test_dl)\n",
    "(out['pred'] * out['target']).sum(1).mean(), np.square(out['pred']-out['target']).sum(1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 13995 / 6.5952e-05 / 1.2645e-04 / 1.3415e-04 / 1.4908e-04\r"
     ]
    }
   ],
   "source": [
    "for latent_dim in [8, 16, 32, 64]:\n",
    "    best_loss = 1e5\n",
    "    model = AutoEncoder(104, latent_dim, encoder_hidden_dim=64, encoder_hidden_layers=4, \n",
    "                        decoder_hidden_dim=64, decoder_hidden_layers=4)\n",
    "    trainer = AETrainer(model, 1e-4, device='cuda')\n",
    "    output_path = f'/home/jhyang/WORKSPACES/MODELS/isyn/AE/train_unique_nn_latent_{latent_dim:02d}'\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    writer = SummaryWriter(output_path)\n",
    "    for epoch in range(50000):\n",
    "        train_loss = trainer.train(train_dl)\n",
    "        valid_loss, valid_output = trainer.test(valid_dl)\n",
    "        writer.add_scalar('Loss/Train', train_loss, epoch+1)\n",
    "        writer.add_scalar('Loss/Valid', valid_loss, epoch+1)\n",
    "        if (epoch + 1)%10 == 0:\n",
    "            test_loss, test_output = trainer.test(test_dl)\n",
    "            writer.add_scalar('Loss/Test', test_loss, epoch+1)\n",
    "            \n",
    "            if (epoch+1)%1000 == 0:\n",
    "                trainer.model.save(output_path, f'{epoch+1:05d}.model')\n",
    "                with open(os.path.join(output_path, f'{epoch+1:05d}.output.valid.pkl'),'wb') as f:\n",
    "                    pickle.dump(valid_output, f)\n",
    "                with open(os.path.join(output_path, f'{epoch+1:05d}.output.test.pkl'),'wb') as f:\n",
    "                    pickle.dump(test_output, f)\n",
    "\n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            trainer.model.save(output_path, 'best.model')\n",
    "            with open(os.path.join(output_path, 'best.output.valid.pkl'),'wb') as f:\n",
    "                pickle.dump(valid_output, f)\n",
    "            test_loss, test_output = trainer.test(test_dl)\n",
    "            with open(os.path.join(output_path, 'best.output.test.pkl'),'wb') as f:\n",
    "                pickle.dump(test_output, f)\n",
    "            with open('best.epoch.txt','w') as f: f.write(str(epoch+1))\n",
    "\n",
    "        print(f'{epoch:6d} / {train_loss:10.4e} / {best_loss:10.4e} / {valid_loss:10.4e} / {test_loss:10.4e}', end='\\r')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(output_path, 'best.output.test.pkl'),'rb') as f:\n",
    "    j = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.473   0.020   0.008\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m500\u001b[39m):\n\u001b[1;32m     19\u001b[0m     t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 20\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_tgt_dl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     t1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     22\u001b[0m     valid_loss, _ \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mtest(valid_dl)\n",
      "Cell \u001b[0;32mIn[6], line 25\u001b[0m, in \u001b[0;36mDefaultTrainer.train\u001b[0;34m(self, dataloader)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     24\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataloader)\n",
      "File \u001b[0;32m~/anaconda3/envs/isyn/lib/python3.9/site-packages/torch/optim/optimizer.py:109\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/isyn/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/isyn/lib/python3.9/site-packages/torch/optim/adamw.py:161\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    157\u001b[0m             max_exp_avg_sqs\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_exp_avg_sq\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    159\u001b[0m         state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 161\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m          \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m          \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m          \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m          \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m          \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m          \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m          \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m          \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m          \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m          \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m          \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/anaconda3/envs/isyn/lib/python3.9/site-packages/torch/optim/adamw.py:218\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    216\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 218\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/isyn/lib/python3.9/site-packages/torch/optim/adamw.py:313\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    311\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m--> 313\u001b[0m \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcdiv_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_avg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mstep_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "model = AutoEncoder(104, 16, encoder_hidden_dim=64, decoder_hidden_dim=64, encoder_hidden_layers=3, decoder_hidden_layers=3)\n",
    "trainer = AETrainer(model, 1e-4, device='cuda')\n",
    "\n",
    "output_path = '../dump/test/ae/target_only'\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "writer = SummaryWriter(output_path)\n",
    "\n",
    "t = []\n",
    "for epoch in range(10000):\n",
    "    t0 = time.time()\n",
    "    train_loss = trainer.train(train_dl)\n",
    "    t1 = time.time()\n",
    "    valid_loss, _ = trainer.test(valid_dl)\n",
    "    t2 = time.time()\n",
    "    test_loss, _ = trainer.test(test_dl)\n",
    "    t3 = time.time()\n",
    "    t.append([t1-t0, t2-t1, t3-t2])\n",
    "    writer.add_scalar('Loss/train', train_loss, epoch+1)\n",
    "    writer.add_scalar('Loss/valid', valid_loss, epoch+1)\n",
    "    writer.add_scalar('Loss/test', test_loss, epoch+1)\n",
    "    print('{:7.3f} {:7.3f} {:7.3f}'.format(*np.mean(t, 0)), end='\\r')\n",
    "# np.array(t)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.utils.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "output_path = '../dump/test/ae/with_precursor'\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "writer = SummaryWriter(output_path)\n",
    "for epoch in range(2000):\n",
    "    train_loss = trainer.train(train_all_dl)\n",
    "    valid_loss, _ = trainer.test(valid_dl)\n",
    "    test_loss, _ = trainer.test(test_dl)\n",
    "    writer.add_scalar('Loss/train', train_loss, epoch+1)\n",
    "    writer.add_scalar('Loss/valid', valid_loss, epoch+1)\n",
    "    writer.add_scalar('Loss/test', test_loss, epoch+1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_trainer = AETrainer(trainer.model, 1e-5)\n",
    "_, out = new_trainer.test(test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#out[1]['comp_feat'], {k:v for k,v in sorted(out[1]['comp_pred'].items(), key=lambda x:x[1], reverse=True)}\n",
    "#out[0]['latent']\n",
    "z = torch.rand((10,5))\n",
    "k = z / z.sum(1).view(-1,1)\n",
    "#z.sum(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isyn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
