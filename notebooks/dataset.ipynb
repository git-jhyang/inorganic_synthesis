{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, json, pickle, gzip, copy, torch, numbers\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from src.data import ReactionDataset, ReactionGraphDataset\n",
    "from src.utils import ActiveElements, MetalElements, Element, AllElements, composit_parser\n",
    "from src.feature import composition_to_feature\n",
    "from pymatgen.core import Composition\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('../data/unique_target.pkl.gz','rb') as f:\n",
    "    unique_target = pickle.load(f)\n",
    "with gzip.open('../data/screened_precursor.pkl.gz','rb') as f:\n",
    "    screened_precursor = pickle.load(f)\n",
    "num_eles = np.zeros((len(ActiveElements), 2))\n",
    "\n",
    "for data in unique_target:\n",
    "    for ele, frac in data['target_comp'].items():\n",
    "        i = ActiveElements.index(ele)\n",
    "        num_eles[i, 0] += data['count']\n",
    "for data in screened_precursor.values():\n",
    "    for ele, frac in data['precursor_comp'].items():\n",
    "        i = ActiveElements.index(ele)\n",
    "        num_eles[i, 1] += data['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmd = {}\n",
    "for fn in os.listdir('../src/elmd'):\n",
    "    if not fn.endswith('json'): continue\n",
    "    elmd[fn.split('.')[0]] = json.load(open(f'../src/elmd/{fn}'))\n",
    "\n",
    "for fn, data in sorted(elmd.items(), key=lambda x: x[0]):\n",
    "    dtype = []\n",
    "    dlen = []\n",
    "#    ele_not_in_table = []\n",
    "    for ele, feat in data.items():\n",
    "        dtype.append(str(type(feat)).split()[1].replace('>','').replace('\\'',''))\n",
    "        if isinstance(feat, (int, float)):\n",
    "            dlen.append(1)\n",
    "        else:\n",
    "            dlen.append(len(feat))\n",
    "#    for ele in elmd['atomic'].keys():\n",
    "#        if ele not in data.keys() and ele not in 'DTUue':\n",
    "#            ele_not_in_table.append((ele, Element(ele).number))\n",
    "    ele_not_in_data = {}\n",
    "    for i, ele in enumerate(ActiveElements):\n",
    "        if ele not in data.keys() and num_eles[i].sum() != 0:\n",
    "            ele_not_in_data[ele] = num_eles[i, :]\n",
    "    print(fn, dtype[0], dlen[0], len(dtype))\n",
    "#    print(ele_not_in_table)\n",
    "    if len(ele_not_in_data) != 0:\n",
    "        print(ele_not_in_data)\n",
    "#    print(ele_not_in_table)\n",
    "#    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ActiveElements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Composition featurization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('../data/unique_ligand.pkl.gz','rb') as f:\n",
    "    unique_ligand = pickle.load(f)\n",
    "with gzip.open('../data/unique_precursor.pkl.gz','rb') as f:\n",
    "    unique_precursor = pickle.load(f)\n",
    "with gzip.open('../data/unique_target.pkl.gz','rb') as f:\n",
    "    unique_target = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.feature import composition_to_feature\n",
    "\n",
    "composition_to_feature({'Li':0.2, 'Co':0.2, 'O':0.6}, feature_type='magpie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgs = {}\n",
    "mask = np.ones(len(unique_precursor), dtype=bool)\n",
    "for ele in MetalElements:\n",
    "    precs = []\n",
    "    for i, prec in enumerate(unique_precursor):\n",
    "        if ele not in prec['precursor_comp'].keys(): continue\n",
    "        precs.append([len(prec['years']), prec['precursor_comp']])\n",
    "        mask[i] = False\n",
    "    precs = sorted(precs, key=lambda x: x[0], reverse=True)\n",
    "    precs = sorted(precs, key=lambda x: len(list(x[1].keys())))\n",
    "    precs = sorted(precs, key=lambda x: tuple(list(x[1].keys())))\n",
    "    for prec in precs:\n",
    "        n = np.min(list(prec[1].values()))\n",
    "        p = '   '.join([f'{e:2s}:{f/n:.2f}' for e, f in prec[1].items()])\n",
    "        print('{:5d} : {}'.format(prec[0], p))\n",
    "    if len(prec) != 0:\n",
    "        print()\n",
    "\n",
    "precs = []\n",
    "for j in np.where(mask)[0]:\n",
    "    prec = unique_precursor[j]\n",
    "    precs.append([len(prec['years']), prec['precursor_comp']])\n",
    "            \n",
    "precs = sorted(precs, key=lambda x: x[0], reverse=True)\n",
    "precs = sorted(precs, key=lambda x: len(list(x[1].keys())))\n",
    "precs = sorted(precs, key=lambda x: tuple(list(x[1].keys())))\n",
    "for prec in precs:\n",
    "    n = np.min(list(prec[1].values()))\n",
    "    p = '   '.join([f'{e:2s}:{f/n:.2f}' for e, f in prec[1].items()])\n",
    "    print('{:5d} : {}'.format(prec[0], p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgs = {}\n",
    "for prec in unique_precursor:\n",
    "    n = len(prec['years'])\n",
    "    metals = {}\n",
    "    non_metals = {}\n",
    "    for e, f in prec['precursor_comp'].items():\n",
    "        if e in MetalElements:\n",
    "            metals.update({e:f})\n",
    "        else:\n",
    "            non_metals.update({e:f})\n",
    "    k_m = tuple(sorted(list(metals.keys()), key=lambda x: Element(x).number))\n",
    "    k_fg = tuple(sorted(list(non_metals.keys()), key=lambda x: Element(x).number))\n",
    "    if k_fg not in fgs.keys():\n",
    "        fgs[k_fg] = {'count':0, 'metals':{}}\n",
    "    if k_m not in fgs[k_fg]['metals']:\n",
    "        fgs[k_fg]['metals'][k_m] = {\n",
    "            'count':0, 'case':[]\n",
    "        }\n",
    "    fgs[k_fg]['count'] += n\n",
    "    fgs[k_fg]['metals'][k_m]['count'] += n\n",
    "    fgs[k_fg]['metals'][k_m]['case'].append([prec['precursor_comp'], n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgs = {k:v for k,v in sorted(fgs.items(), key=lambda x: len(x[0]))}\n",
    "fgs = {k:v for k,v in sorted(fgs.items(), key=lambda x: x[0])}\n",
    "fgs = {k:v for k,v in sorted(fgs.items(), key=lambda x: x[1]['count'])}\n",
    "for k, v in fgs.items():\n",
    "    m = list(v['metals'].keys())\n",
    "    print(k, v['count'], f'{len(m)}/{len(MetalElements)}')\n",
    "    print(m)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unique_reaction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43munique_reaction\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'unique_reaction' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precursor dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS = ReactionDataset()\n",
    "DS.from_file('../data/screened_unique_reaction.pkl.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embedding 및 label 관리를 위해 따로 만들 필요가 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#완성 후 삭제함\n",
    "from src.feature import PrecursorDataset\n",
    "PDS = PrecursorDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### precursor mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = np.zeros((PDS.NUM_LABEL, len(MetalElements)+1), dtype=bool)\n",
    "for i, prec in enumerate(PDS.precursor_source):\n",
    "    for ele in prec['precursor_comp'].keys():\n",
    "        if ele in MetalElements:\n",
    "            j = MetalElements.index(ele)\n",
    "            mat[i, j] = True\n",
    "    if mat[i].sum() == 0:\n",
    "        mat[i, -1] = True\n",
    "mat = mat.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.matmul(mat.T, mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = -1\n",
    "js = np.where(mat[k])[0]\n",
    "print(MetalElements[k] if k != -1 else 'None', mat[k].sum())\n",
    "print(js)\n",
    "for i, j in enumerate(js):\n",
    "    print('{:2d} {:4d} {:2d}  {}'.format(i, j, int(((z[j] & mat[k]) != mat[k]).sum() == 0), PDS.precursor_source[j]['precursor_comp']))\n",
    "#np.where(z[0]), np.where(z[43]), np.where(z[180])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in np.where(mat[:, k])[0]:\n",
    "    print(PDS.precursor_source[j]['precursor_comp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('../data/screened_unique_reaction.pkl.gz','rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "pstrs = []\n",
    "for data in dataset:\n",
    "    for prec in data['precursor_comp']:\n",
    "        pstr = composit_parser(prec)\n",
    "        if pstr not in pstrs:\n",
    "            pstrs.append(pstr)\n",
    "PDS.update(pstrs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in np.where(PDS.precursor_mask[-1])[0]:\n",
    "    print(j, PDS.label_to_precursor[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_precursor_mask_from_target(self, target):\n",
    "    mask = self.precursor_mask[-1].copy()\n",
    "    for ele in target.keys():\n",
    "        if ele in MetalElements:\n",
    "            mask = mask | self.precursor_mask[MetalElements.index(ele)]\n",
    "    return mask\n",
    "\n",
    "target = dataset[0]['target_comp']\n",
    "mask = get_precursor_mask_from_target(PDS, target)\n",
    "print(target)\n",
    "for j in np.where(mask)[0]:\n",
    "#    print(j)\n",
    "    out = PDS.get_precursor_info(j)[1]\n",
    "    if isinstance(out, dict):\n",
    "        print(out['precursor_comp'])\n",
    "    else:\n",
    "        print(out)\n",
    "    #['precursor_comp']\n",
    "#PDS.label_to_precursor[j]\n",
    "#PDS.get_precursor_info(9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### precursor mask의 적합성 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('../data/screened_unique_reaction.pkl.gz','rb') as f:\n",
    "    dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in dataset:\n",
    "    m = np.zeros((len(MetalElements), 2), dtype=int)\n",
    "    for ele in data['target_comp'].keys():\n",
    "        if ele not in MetalElements: continue\n",
    "        i = MetalElements.index(ele)\n",
    "        m[i,0] += 1 \n",
    "    for prec in data['precursor_comp']:\n",
    "        for ele in prec.keys():\n",
    "            if ele not in MetalElements: continue\n",
    "            i = MetalElements.index(ele)\n",
    "            m[i,1] += 1\n",
    "    i, j = m.sum(0)\n",
    "    if (i != j) and (np.sum(m[:, 1][m[:, 0] != 0] == 0) != 0):\n",
    "        print(m[m[:, 1] != 0].T)\n",
    "\n",
    "# target에 있는 모든 metal element는 precursor에 포함되어 있음.\n",
    "# precursor에 있는 모든 metal element는 target에 포함되어 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precursor 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('../data/unique_reaction.pkl.gz','rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "    \n",
    "labels = []\n",
    "coprecursorset = []\n",
    "for d in dataset:\n",
    "    precursor_set = {}\n",
    "    for p in d['precursor_comp']:\n",
    "        pstr = composit_parser(p)\n",
    "        if pstr not in PDS.precursor_to_label.keys(): continue\n",
    "        labels.append(PDS.precursor_to_label[pstr])\n",
    "        metal = [e for e in p.keys() if e in MetalElements]\n",
    "        if len(metal) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            metal = metal[0]\n",
    "        if metal not in precursor_set.keys():\n",
    "            precursor_set[metal] = []\n",
    "        precursor_set[metal].append(pstr)\n",
    "    for v in precursor_set.values():\n",
    "        if len(v) > 1:\n",
    "            coprecursorset.append(v)\n",
    "\n",
    "counts = np.zeros(500)\n",
    "for i, c in zip(*np.unique(labels, return_counts=True)):\n",
    "    counts[i] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique([len(c) for c in coprecursorset], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_precs = []\n",
    "# for data in dataset:\n",
    "#     for prec in data['precursor_comp']:\n",
    "#         pstr = composit_parser(prec)\n",
    "#         if pstr in active_precs:\n",
    "#             continue\n",
    "#         active_precs.append(pstr)\n",
    "# PDS.update(active_precs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.feature import MetalElements\n",
    "k = 0\n",
    "for i, mask in enumerate(PDS.precursor_mask):\n",
    "    if mask.sum() == 0: continue\n",
    "    js = np.where(mask)[0]\n",
    "    k += 1\n",
    "    #if i < len(MetalElements) and MetalElements[i] not in 'PuNp': continue\n",
    "    if len(js) < 10: continue\n",
    "    print(k, MetalElements[i] if i < len(MetalElements) else 'None', '-'*50)\n",
    "    print(''.join([f'{j:4d}' for j in js]))\n",
    "    print(''.join([f'{counts[j]:4.0f}' for j in js]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_types = ['composit', 'cgcnn', 'magpie_sc', 'mat2vec', 'matscholar', 'megnet16']\n",
    "full_vectors = {ftype: np.vstack([composition_to_feature(prec['precursor_comp'], ftype) for prec in PDS.precursor_source]) for ftype in feat_types}\n",
    "fg_vectors = {ftype: np.vstack([composition_to_feature({k:v for k,v in prec['precursor_comp'].items() if k not in MetalElements}, ftype) for prec in PDS.precursor_source]) for ftype in feat_types}\n",
    "fgs = np.array([composit_parser({k:v for k,v in prec['precursor_comp'].items() if k not in MetalElements}) for prec in PDS.precursor_source])\n",
    "element_source = [np.where(m)[0][0] if m.sum() != 0 else -1 for m in PDS.precursor_mask[:-1, :-2].T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(fg_vectors['composit'] != 0).sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "labels = {}\n",
    "for ftype in feat_types:\n",
    "    for n_cluster in [10, 15, 20, 25]:        \n",
    "        labels[f'{ftype}+full+{n_cluster}'] = []\n",
    "        labels[f'{ftype}+fg+{n_cluster}'] = []\n",
    "        for seed in range(1000):\n",
    "            full_labels = KMeans(n_cluster, random_state=seed, n_init='auto').fit_predict(full_vectors[ftype])\n",
    "            fg_labels = KMeans(n_cluster, random_state=seed, n_init='auto').fit_predict(fg_vectors[ftype])\n",
    "            labels[f'{ftype}+full+{n_cluster}'].append(full_labels)\n",
    "            labels[f'{ftype}+fg+{n_cluster}'].append(fg_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix(data, cutoff=50):\n",
    "    matrix = np.zeros((len(data[0]), len(data[0])))\n",
    "    for labels in data[:cutoff]:\n",
    "        for i, label_i in enumerate(labels):\n",
    "            for j, label_j in enumerate(labels[i+1:]):\n",
    "                if label_i != label_j: continue\n",
    "                matrix[i,i+j+1] += 1\n",
    "                matrix[i+j+1,i] += 1\n",
    "    return matrix\n",
    "\n",
    "coassignment_matrices = {}\n",
    "consensus_labels = {}\n",
    "for ftype, label in labels.items():\n",
    "    for n in [50, 100, 200, 500, 1000]:\n",
    "        coassignment_matrices[f'{ftype}+{n}'] = get_matrix(label, n)\n",
    "        agc = AgglomerativeClustering(n_clusters=8, metric='precomputed', linkage='average')\n",
    "        consensus_labels[f'{ftype}+{n}'] = agc.fit_predict(1 - coassignment_matrices[f'{ftype}+{n}'] / n)\n",
    "\n",
    "with open('../dump/coassignment_matrices.pkl','wb') as f:\n",
    "    pickle.dump(coassignment_matrices, f)\n",
    "with open('../dump/consensus_labels.pkl','wb') as f:\n",
    "    pickle.dump(consensus_labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.pcolormesh(coassignment_matrices['cgcnn+fg+10+100'])\n",
    "mat = get_matrix(np.vstack([v for v in labels.values()]), cutoff=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dump/coassignment_matrix_all.pkl','wb') as f:\n",
    "    pickle.dump(mat, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (prec, count) in enumerate(zip(*np.unique(fgs, return_counts=True))):\n",
    "    print(f'{i:3d} - {count:3d} : {prec:30s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agc = AgglomerativeClustering(n_clusters=5, metric='precomputed', linkage='average')\n",
    "label = agc.fit_predict(1 - mat / mat.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = 0.23529, 0.70588\n",
    "c = 1 - a - b\n",
    "1, 4, 12\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(label, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dump/coassignment_matrices.pkl','rb') as f:\n",
    "    coassignment_matrices = pickle.load(f)\n",
    "with open('../dump/consensus_labels.pkl','rb') as f:\n",
    "    consensus_labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(consensus_labels['composit+full+20+500'], return_counts=True))\n",
    "print(np.unique(consensus_labels['composit+full+20+1000'], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(consensus_labels['composit+fg+10+50'], return_counts=True))\n",
    "print(np.unique(consensus_labels['composit+fg+10+1000'], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_labels['composit+fg+10+50'][consensus_labels['composit+fg+10+1000'] == 3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def align_labels(labels_1, labels_2, num_clusters=8):\n",
    "    cost_matrix = np.zeros((num_clusters, num_clusters))\n",
    "    for i in range(num_clusters):\n",
    "        for j in range(num_clusters):\n",
    "            cost_matrix[i, j] = np.sum((labels_1 == i) & (labels_2 == j))\n",
    "    _, col_ind = linear_sum_assignment(-cost_matrix)\n",
    "    new_labels_2 = np.zeros_like(labels_2)\n",
    "    for i, idx in enumerate(col_ind):\n",
    "        new_labels_2[labels_2 == i] = idx\n",
    "    return new_labels_2\n",
    "\n",
    "for desc_0 in consensus_labels.keys():\n",
    "    labels_1 = consensus_labels[desc_0]\n",
    "    prefix = '+'.join(desc_0.split('+')[:2])\n",
    "    for desc, labels in consensus_labels.items():\n",
    "        if desc == desc_0: continue\n",
    "        if not desc.startswith(prefix): continue\n",
    "#    if not desc.startswith('composit+full'):\n",
    "#        continue\n",
    "        labels_2 = align_labels(labels_1, labels)\n",
    "        consensus_labels[desc] = labels_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs = consensus_labels.keys()\n",
    "for desc_i in descs:\n",
    "    prefix = '+'.join(desc_i.split('+')[:2])\n",
    "    labels_i = consensus_labels[desc_i]\n",
    "    for desc_j in descs:\n",
    "        if not desc_j.startswith(prefix): continue\n",
    "        labels_j = consensus_labels[desc_j]\n",
    "\n",
    "#labels_3 = align_labels(labels_1, labels_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eos and sos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDS.update(DS)\n",
    "#PDS.source_to_label[DS[0].labels]\n",
    "\n",
    "#PDS.label_to_precursor[412]\n",
    "#PDS.source_to_label[DS[0].labels], DS[0].labels\n",
    "PDS.get_precursor_data('SOS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip, pickle\n",
    "path = '../data/screened_precursor.pkl.gz'\n",
    "with gzip.open(path, 'rb') as f:\n",
    "    unique_precursor = pickle.load(f)\n",
    "unique_precursor[:4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional Group Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('../data/unique_precursor.pkl.gz','rb') as f:\n",
    "    unique_precursor = pickle.load(f)    \n",
    "with gzip.open('../data/screened_precursor.pkl.gz','rb') as f:\n",
    "    screened_precursor = pickle.load(f)\n",
    "with gzip.open('../data/unique_reaction.pkl.gz','rb') as f:\n",
    "    unique_reaction = pickle.load(f)\n",
    "with gzip.open('../data/screened_unique_reaction.pkl.gz','rb') as f:\n",
    "    screened_unique_reaction = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from src.feature import MetalElements, AllElements\n",
    "\n",
    "class LigandTemplateDataset:\n",
    "    def __init__(self, \n",
    "                 feat_type:str = 'composit',\n",
    "                 by_fraction:bool = True,\n",
    "                 *args, **kwargs):\n",
    "        self._feat_type = feat_type\n",
    "        self._by_fraction = by_fraction\n",
    "\n",
    "#        path = os.path.join(os.path.dirname(os.path.abspath(__file__)), '../data/screened_precursor.pkl.gz')\n",
    "        path = '../data/screened_precursor.pkl.gz'\n",
    "\n",
    "        with gzip.open(path, 'rb') as f:\n",
    "            self._precursor_source = pickle.load(f)\n",
    "        self._active_precursors = [p['precursor_str'] for p in self._precursor_source]\n",
    "        self._precursor_to_source = {c:i for i,c in enumerate(self._active_precursors)}\n",
    "#        self._source_vecs = np.vstack([composition_to_feature(c) for c in self._active_precursors])\n",
    "        self._metal_indexer = {'none': 0}\n",
    "        self._metal_indexer.update({metal:i+1 for i,metal in enumerate(MetalElements)})\n",
    "        self.update()\n",
    "\n",
    "    def update(self, active_precursors=None):\n",
    "        if not isinstance(active_precursors, (list, np.ndarray, tuple, set)):\n",
    "            active_precursors = self._active_precursors\n",
    "        _active_precursors = []\n",
    "        self._ligand_dict = {}\n",
    "        for i_src, precursor in enumerate(self._precursor_source):\n",
    "            if precursor['precursor_str'] not in active_precursors:\n",
    "                continue\n",
    "            _active_precursors.append(precursor['precursor_str'])\n",
    "            n_total = np.sum(list(precursor['precursor_comp'].values()))\n",
    "            i_metal = 0\n",
    "            non_metal = {}\n",
    "            for ele, n in precursor['precursor_comp'].items():\n",
    "                if ele in MetalElements:\n",
    "                    i_metal = self._metal_indexer[ele]\n",
    "                else:\n",
    "                    non_metal[ele] = n/n_total\n",
    "            ligand_str = composit_parser(non_metal)\n",
    "            if ligand_str not in self._ligand_dict.keys():\n",
    "                self._ligand_dict[ligand_str] = {\n",
    "                    'label':None, \n",
    "                    'composition':non_metal,\n",
    "                    'embedding': composition_to_feature(composit_dict = non_metal, \n",
    "                                                        feature_type = self._feat_type,\n",
    "                                                        by_fraction = self._by_fraction,\n",
    "                                                        norm=False).reshape(1,-1),\n",
    "                    'metals':[]}\n",
    "            self._ligand_dict[ligand_str]['metals'].append((i_metal, i_src))\n",
    "\n",
    "        self.NUM_LABEL = len(self._ligand_dict)\n",
    "        self._active_precursors = _active_precursors.copy()\n",
    "\n",
    "        self._source_to_label = np.zeros((len(self._precursor_source), 2), dtype=int)\n",
    "        self._label_to_source = - np.ones((len(MetalElements)+1, self.NUM_LABEL), dtype=int)\n",
    "        self._ligand_str = list(self._ligand_dict.keys())\n",
    "        for j, ligand_info in enumerate(self._ligand_dict.values()):\n",
    "            ligand_info['label'] = j\n",
    "            for i, i_source in ligand_info['metals']:\n",
    "                self._label_to_source[i, j] = i_source\n",
    "                self._source_to_label[i_source] = i, j\n",
    "\n",
    "    def save(self, path, fn='precursor_data.json'):\n",
    "        info = {\n",
    "            'feat_type': self._feat_type,\n",
    "            'by_fraction': self._by_fraction,\n",
    "            'active_precursors': self._active_precursors,\n",
    "        }\n",
    "        with open(os.path.join(path, fn), 'w') as f:\n",
    "            json.dump(info, f, indent=4)\n",
    "    \n",
    "    def load(self, path, fn='precursor_data.json'):\n",
    "        with open(os.path.join(path, fn), 'r') as f:\n",
    "            info = json.load(f)\n",
    "        self.__init__(feat_type = info['feat_type'],\n",
    "                      by_fraction = info['by_fraction'],\n",
    "                      norm = info['norm'])\n",
    "        self.update(info['active_precursors'])\n",
    "        return self\n",
    "\n",
    "    def _check_valid_precursor(self, *args, exit=True):\n",
    "        i_src = None\n",
    "        if len(args) == 1:\n",
    "            if isinstance(args[0], dict):\n",
    "                div = np.sum(list(args[0].values()))\n",
    "                precursor = composit_parser({e:n/div for e,n in args[0].items()})\n",
    "            elif isinstance(args[0], str):\n",
    "                precursor = args[0]\n",
    "            elif exit:\n",
    "                raise ValueError('Precursor must be either `dict` or `str`, got', type(args[0]))\n",
    "            try:\n",
    "                i_src = self._precursor_to_source[precursor]\n",
    "            except:\n",
    "                i_src = None\n",
    "        elif len(args) > 1:\n",
    "            metal, ligand = args[:2]\n",
    "            i_metal, i_ligand = None, None\n",
    "            if isinstance(metal, str) and (metal in self._metal_indexer):\n",
    "                i_metal = self._metal_indexer[metal]\n",
    "            elif isinstance(metal, numbers.Integral) and metal < len(MetalElements) + 1:\n",
    "                i_metal = metal\n",
    "            if isinstance(ligand, str) and (ligand in self._ligand_dict.keys()):\n",
    "                i_ligand = self._ligand_dict[ligand]['label']\n",
    "            elif isinstance(ligand, numbers.Integral) and ligand < len(self._ligand_dict):\n",
    "                i_ligand = ligand\n",
    "            if (i_metal is None) or (i_ligand is None):\n",
    "                i_src = None\n",
    "            else:\n",
    "                i_src = self._label_to_source[i_metal, i_ligand]\n",
    "            if i_src == -1:\n",
    "                i_src = None\n",
    "        if (i_src is None) and exit:\n",
    "            raise ValueError('Invalid precursor', args)\n",
    "        return i_src        \n",
    "\n",
    "    def to_label(self, *args):\n",
    "        i_source = self._check_valid_precursor(args)\n",
    "        _, label = self._source_to_label[i_source]\n",
    "        return label\n",
    "\n",
    "    def get_embedding(self, *args):\n",
    "        i_src = self._check_valid_precursor(args, exit=False)\n",
    "        if i_src is None:\n",
    "            return composition_to_feature({}, feature_type=self._feat_type, by_fraction=self._by_fraction)\n",
    "        else:\n",
    "            _, i_ligand = self._source_to_label[i_src]\n",
    "            return self._ligand_dict[self._ligand_str[i_ligand]]['embedding']\n",
    "    \n",
    "    def get_info(self, *args):\n",
    "        i_source = self._check_valid_precursor(*args)\n",
    "        return self._precursor_source[i_source]\n",
    "    \n",
    "    def get_mask(self, metal):\n",
    "        if metal in MetalElements:\n",
    "            i_metal = MetalElements.index(metal) + 1\n",
    "        else:\n",
    "            i_metal = 0\n",
    "        return (self._label_to_source[i_metal] != -1).reshape(1,-1)\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'feature_type': self._feat_type, \n",
    "            'NUM_LABEL': self.NUM_LABEL,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = LigandTemplateDataset()\n",
    "#test.update([p['precursor_str'] for p in screened_precursor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.repeat(test.get_embedding(), 4, axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(test._label_to_source[0] != -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask[0]\n",
    "metals, mask = test.get_ligand_mask_from_target({'Ti':0.111, 'Li':0.3333, 'Co':0.3333, 'O':0.666667})\n",
    "for mele, m in zip(metals, mask):\n",
    "    for (ligand, metal), active in zip(test._ligand_dict.items(), m):\n",
    "        if not active: continue\n",
    "        print(mele in [_m[0] for _m in metal['metals']], mele, '   {:3f}   '.format(np.sum(list(metal['composition'].values()))), ligand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### how to manage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "count_precursor = {}\n",
    "for data in unique_reactions:\n",
    "    for p in data['precursor_comp']:\n",
    "        comp = Composition(p)\n",
    "        new_comp = str(Composition(comp.get_integer_formula_and_factor()[0]))\n",
    "        if new_comp not in count_precursor.keys():\n",
    "            count_precursor[new_comp] = 0\n",
    "        count_precursor[new_comp] += 1\n",
    "\n",
    "prec_comps = []\n",
    "for prec in screened_precursor:\n",
    "    comp = Composition(prec['precursor_comp'].items())\n",
    "    new_comp = Composition(comp.get_integer_formula_and_factor()[0]).as_dict()\n",
    "    prec_comps.append(new_comp)\n",
    "    for e, f in new_comp.items():\n",
    "        if e not in MetalElements: continue\n",
    "        if f != 1: print(new_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgs_int = {}\n",
    "fgs_norm_full  = {}\n",
    "fgs_norm_metal = {}\n",
    "for p in prec_comps:\n",
    "    pstr = str(Composition(p))\n",
    "    pc = count_precursor[pstr]\n",
    "    ns = 0\n",
    "    metal_n = 1\n",
    "    others = {}\n",
    "    metal = 'none'\n",
    "    metal_ele = 'none'\n",
    "    for e,n in p.items():\n",
    "        ns += n\n",
    "        if e in MetalElements:\n",
    "            metal = f'{e}{n:.0f}'\n",
    "            metal_ele = e\n",
    "            metal_n = n\n",
    "        else:\n",
    "            others[e] = n    \n",
    "    norm_by_metal = {k:v/metal_n for k,v in others.items()}\n",
    "    norm_by_all = {k:v/ns for k,v in others.items()}\n",
    "    intkey = str(Composition(others))\n",
    "    mfrkey = str(Composition(norm_by_metal))\n",
    "    frkey = str(Composition(norm_by_all))\n",
    "\n",
    "    if intkey not in fgs_int.keys():\n",
    "        fgs_int[intkey] = []\n",
    "    if frkey not in fgs_norm_full.keys():\n",
    "        fgs_norm_full[frkey] = []\n",
    "    if mfrkey not in fgs_norm_metal.keys():\n",
    "        fgs_norm_metal[mfrkey] = []\n",
    "    fgs_int[intkey].append((metal, pc))\n",
    "    fgs_norm_full[frkey].append((metal_ele, pc))\n",
    "    fgs_norm_metal[mfrkey].append((metal_ele, pc))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metal_int = {}\n",
    "metal_fr = {}\n",
    "for e in MetalElements:\n",
    "    metal_int[e] = {}\n",
    "    metal_fr[e] = {}\n",
    "    for prec in prec_comps:\n",
    "        if e not in prec.keys():\n",
    "            continue\n",
    "        ns = np.sum([v for v in prec.values()])\n",
    "        mc = [v for e,v in prec.items() if e in MetalElements][0]\n",
    "        prec_str = str(Composition(prec))\n",
    "        fg_int = str(Composition({e:v for e,v in prec.items() if e not in MetalElements}))\n",
    "        fg_fr  = str(Composition({e:v/ns for e,v in prec.items() if e not in MetalElements}))\n",
    "        if fg_int not in metal_int[e].keys():\n",
    "            metal_int[e][fg_int] = [0, []]\n",
    "        if fg_fr not in metal_fr[e].keys():\n",
    "            metal_fr[e][fg_fr] = [0, []]\n",
    "        metal_int[e][fg_int][0] += count_precursor[prec_str]\n",
    "        metal_int[e][fg_int][1].append(mc)\n",
    "        metal_fr[e][fg_fr][0] += count_precursor[prec_str]\n",
    "        metal_fr[e][fg_fr][1].append(mc)\n",
    "    if len(metal_int[e]) > 1:\n",
    "        print(e, '-' * 50)\n",
    "        for p, (c, mcs) in metal_int[e].items():\n",
    "            print(f'    {p:15s} : {c:4d} / {mcs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "num = re.compile(r'\\d')\n",
    "for data_dict in [fgs_int, fgs_norm_full, fgs_norm_metal]:\n",
    "    for fg, metals in data_dict.items():\n",
    "        for i, (metal_i, c_i) in enumerate(metals):\n",
    "            ele_i = num.sub('', metal_i)\n",
    "            for j, (metal_j, c_j) in enumerate(metals[i+1:]):\n",
    "                ele_j = num.sub('', metal_j)\n",
    "                if ele_i == ele_j:\n",
    "                    print(fg, '-', metal_i, c_i, metal_j, c_j)\n",
    "    print('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_by_fg(ax, data):\n",
    "    fgs, n_metals, n_precs = np.array([[fg, len(metals), np.sum([m[1] for m in metals])] for fg, metals in data.items()]).T\n",
    "    n_precs = n_precs.astype(float)\n",
    "    n_metals = n_metals.astype(float)\n",
    "    o1 = np.argsort(n_precs)[::-1]\n",
    "    o = sorted(o1, key=lambda x: n_metals[x], reverse=True)\n",
    "    x = np.arange(len(n_metals))\n",
    "    ax2 = ax.twinx()\n",
    "    ax.plot(x, n_metals[o], '-o', color='b')\n",
    "    for i in range(0, len(n_metals), 10):\n",
    "        ax.axvline(i, ls='--', color='k', lw=0.5)\n",
    "    for i in range(0,70,10):\n",
    "        ax.axhline(i, ls='--', color='k', lw=0.5)\n",
    "    ax2.plot(x, n_precs[o], '-o', color='r')\n",
    "    ax2.set_yscale('log')\n",
    "    ax2.set_ylim([2, 1e5])\n",
    "    ax.set_xlabel('Ligands', fontsize=14)\n",
    "    ax.set_ylabel('# of Metal elements', fontsize=14, color='b')\n",
    "    ax2.set_ylabel('Usage', fontsize=14, color='r')\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(1,1,figsize=(11,4))\n",
    "draw_by_fg(ax, fgs_int)\n",
    "f, ax = plt.subplots(1,1,figsize=(11,4))\n",
    "draw_by_fg(ax, fgs_norm_metal)\n",
    "f, ax = plt.subplots(1,1,figsize=(11,4))\n",
    "draw_by_fg(ax, fgs_norm_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = np.zeros((len(MetalElements)+1, len(fgs_norm_full))) + 1e-4\n",
    "for j, metals in enumerate(sorted(fgs_norm_full.values(), key=lambda x: len(x), reverse=True)):\n",
    "    for metal, v in metals:\n",
    "        if metal == 'none':\n",
    "            i = 0\n",
    "        else:\n",
    "            i = MetalElements.index(metal) + 1\n",
    "        mat[i,j] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap('viridis')\n",
    "cmap.set_under([0.7,0.7,0.7])\n",
    "f, ax = plt.subplots(1,1,figsize=(10,7))\n",
    "ax.pcolormesh(np.log10(mat), cmap=cmap, vmin=0)\n",
    "ax.set_ylabel('Metals', fontsize=14)\n",
    "ax.set_xlabel('Ligands', fontsize=14)\n",
    "for i in range(1, 12):\n",
    "    ax.axvline(i * 10, ls='--', color='k', lw=0.5)\n",
    "for i in range(1, 9):\n",
    "    ax.axhline(i * 10, ls='--', color='k', lw=0.5)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 문제점\n",
    "  - 금속 기준으로 normalize를 할 경우 metal-free precursor의 예측이 어려워짐\n",
    "  - integer로 변경해서 사용 할 경우 큰 수가 나오는 경우가 있음 (200 이상)\n",
    "- intrinsic한 parsing error로 인한 한계도 있음. 그냥 fractional로 진행\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def draw_by_metal(ax, data):\n",
    "    _, n_fgs, n_precs = np.array([[metal, len(fgs), np.sum([m[0] for m in fgs.values()])] for metal, fgs in data.items() if len(fgs) != 0]).T\n",
    "    o1 = np.argsort(n_precs.astype(float))[::-1]\n",
    "    o = sorted(o1, key=lambda x: n_fgs.astype(float)[x], reverse=True)\n",
    "\n",
    "    x = np.arange(len(n_fgs))\n",
    "    ax2 = ax.twinx()\n",
    "    ax.plot(x, n_fgs.astype(float)[o], '-o', color='b')\n",
    "    ax2.plot(x, n_precs.astype(float)[o], '-o', color='r')\n",
    "    ax2.set_yscale('log')\n",
    "    ax.set_ylim([-1,23])\n",
    "    ax2.set_ylim([2, 1e4])\n",
    "    for i in range(0, len(n_fgs), 5):\n",
    "        ax.axvline(i, ls='--', color='k', lw=0.5)\n",
    "    for i in range(0,2,5):\n",
    "        ax.axhline(i, ls='--', color='k', lw=0.5)\n",
    "    ax.set_ylabel('# of ligands', fontsize=14, color='b')\n",
    "    ax.set_xlabel('Metal elements', fontsize=14)\n",
    "    ax2.set_ylabel('Usage', fontsize=14, color='r')\n",
    "\n",
    "f, ax = plt.subplots(1,1,figsize=(11,4))\n",
    "draw_by_metal(ax, metal_int)\n",
    "f, ax = plt.subplots(1,1,figsize=(11,4))\n",
    "draw_by_metal(ax, metal_fr)\n",
    "f.subplots_adjust(hspace=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "precursor_source = {p['precursor_str']:[p['count'], p['count_rxn'], len(np.unique(p['dois']))] for p in unique_precursor}\n",
    "\n",
    "ligand_dict = {}\n",
    "counter = np.zeros((len(MetalElements)+1, 1, 10))\n",
    "#for rxn in unique_reaction:\n",
    "for rxn in screened_unique_reaction:\n",
    "    for p in rxn['precursor_comp']:\n",
    "        pstr = composit_parser(p)\n",
    "        non_metal = {}\n",
    "        i_metal = 0\n",
    "        for ele, n in p.items():\n",
    "            if ele in MetalElements:\n",
    "                i_metal = MetalElements.index(ele) + 1\n",
    "            else:\n",
    "                non_metal[ele] = n\n",
    "        ligand_str = composit_parser(non_metal, norm=False)\n",
    "        if ligand_str not in ligand_dict.keys():\n",
    "            ligand_dict[ligand_str] = len(ligand_dict)\n",
    "            counter = np.concatenate([counter, np.zeros((len(MetalElements)+1, 1, 10))], axis=1)\n",
    "        i_ligand = ligand_dict[ligand_str]\n",
    "        counter[i_metal, i_ligand, 0] += 1/rxn['count']\n",
    "        counter[i_metal, i_ligand, 1] += 1\n",
    "        counter[i_metal, i_ligand, 2] += len(rxn['dois'])\n",
    "        counter[i_metal, i_ligand, 3] = precursor_source[pstr][0]\n",
    "        counter[i_metal, i_ligand, 4] = precursor_source[pstr][1]\n",
    "        counter[i_metal, i_ligand, 5] = precursor_source[pstr][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 2 artists>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 61\n",
    "mask = counter[i, :, 0] != 0\n",
    "\n",
    "y = counter[i, mask, 0] \n",
    "m = 1 / np.power(counter[i, mask, 3], 1/1.2)\n",
    "n = 1 #/ np.max(m)\n",
    "\n",
    "f, axs = plt.subplots(1,3,figsize=(15,4))\n",
    "axs[0].bar(np.arange(mask.sum()), y * m * n)\n",
    "axs[1].bar(np.arange(mask.sum()), y)\n",
    "axs[1].set_yscale('log')\n",
    "axs[2].bar(np.arange(mask.sum()), m * n)\n",
    "#counter[0].T[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data object test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "import torch, os, gzip, pickle\n",
    "from src.data import ReactionData\n",
    "from typing import Dict, List\n",
    "from src.utils import ActiveElements, MetalElements, Element\n",
    "from src.feature import composition_to_feature\n",
    "\n",
    "with gzip.open('../data/screened_conditional_reaction.pkl.gz','rb') as f:\n",
    "    cond_rxn = pickle.load(f)\n",
    "with gzip.open('../data/screened_unique_reaction.pkl.gz','rb') as f:\n",
    "    uniq_rxn = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### speed test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnc1(x):\n",
    "    return (x + 1) ** 3\n",
    "def fnc2(x):\n",
    "    return (x / 2 + 1) ** 0.5\n",
    "def fnc3(x):\n",
    "    return (x - 1) ** 2 / 2\n",
    "def fnc4(x):\n",
    "    return (x + 2) ** 2\n",
    "\n",
    "def cfn1(n, x):\n",
    "    d1 = []\n",
    "    d2 = []\n",
    "    d3 = []\n",
    "    d4 = []\n",
    "    for i in range(n):\n",
    "        if x:\n",
    "            v2 = fnc2(i)\n",
    "            v1 = fnc1(i)\n",
    "            d1.append(v1)\n",
    "            d2.append(v2)\n",
    "        if not x:\n",
    "            v3 = fnc3(i)\n",
    "            v4 = fnc4(i)\n",
    "            d3.append(v3)\n",
    "            d4.append(v4)\n",
    "    return d1, d2, d3, d4\n",
    "\n",
    "def cfn2(n, x):\n",
    "    d1 = []\n",
    "    d2 = []\n",
    "    d3 = []\n",
    "    d4 = []    \n",
    "    if x:\n",
    "        d1 = [fnc1(i) for i in range(n)]\n",
    "        d2 = [fnc2(i) for i in range(n)]\n",
    "    if not x:\n",
    "        d3 = [fnc3(i) for i in range(n)]\n",
    "        d4 = [fnc4(i) for i in range(n)]\n",
    "    return d1, d2, d3, d4\n",
    "\n",
    "%timeit cfn1(500, True)\n",
    "%timeit cfn2(500, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for i, rxn in enumerate(uniq_rxn):\n",
    "    eles = {}\n",
    "    for prec in rxn['precursor_comp']:\n",
    "        metal_ele = tuple([e for e in prec.keys() if e in MetalElements])\n",
    "        if metal_ele not in eles.keys():\n",
    "            eles[metal_ele] = 0\n",
    "        eles[metal_ele] += 1\n",
    "#    if np.max(list(eles.values())) > 2:\n",
    "#        print(i, eles)\n",
    "    if tuple([]) in eles:\n",
    "        cnt += 1\n",
    "        print(i, eles)\n",
    "print(cnt, len(uniq_rxn))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_rxn[77]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_rxn[29022 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_rxn[7168 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_rxn[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reaction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = uniq_rxn[0]\n",
    "rxn_data = ReactionData(data = data,\n",
    "                        feat_type = 'composit',\n",
    "                        target_comp = data['target_comp'],\n",
    "                        precursor_comps = data['precursor_comp'],\n",
    "#                        conditions = ['heat_temp'],\n",
    "#                        condition_values = [data['target_comp']['heat_temp']['median']],\n",
    "                        weights = None)\n",
    "\n",
    "rxn_data.precursor_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxn_data.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rxn_data.metal_feat\n",
    "#rxn_data.target_feat\n",
    "for f in rxn_data.precursor_feat.numpy():\n",
    "    ii = np.where(f)[0]\n",
    "    print(ii, [(ActiveElements[i], f[i]) for i in ii])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxn_data.precursor_feat[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphData(ReactionData):\n",
    "    def __init__(self, \n",
    "                 data : Dict = {},\n",
    "                 feat_type : str = 'composit',\n",
    "                 target_comp : Dict = {},\n",
    "                 precursor_comps : List[Dict] = [],\n",
    "                 conditions : List[str] = [],\n",
    "                 condition_values : List[float] = [],\n",
    "                 weights : float = None,\n",
    "                 *args, **kwargs):\n",
    "        \n",
    "        super().__init__(data = data,\n",
    "                         feat_type = feat_type,\n",
    "                         target_comp = target_comp,\n",
    "                         precursor_comps = precursor_comps,\n",
    "                         conditions = conditions,\n",
    "                         condition_values = condition_values,\n",
    "                         weights = weights,\n",
    "                         *args, **kwargs)\n",
    "\n",
    "        # graph \n",
    "        self._feature_attrs.extend(['edge_feat','edge_index'])\n",
    "        edge_index = []\n",
    "        edge_feat = []\n",
    "        for i, metal_i in enumerate(self.metal_comp):\n",
    "            for j, metal_j in enumerate(self.metal_comp):\n",
    "                edge_index.append([i,j])\n",
    "                if i == j:\n",
    "                    edge_feat.append(self.target_feat)\n",
    "                else:\n",
    "                    edge_comp = {}\n",
    "                    for e, f in self.target_comp.items():\n",
    "                        if e in metal_i.keys() or e in metal_j.keys():\n",
    "                            edge_comp.update({e:f})\n",
    "                        elif e in MetalElements:\n",
    "                            continue\n",
    "                        elif len(metal_i) == 0 or len(metal_j) == 0:\n",
    "                            edge_comp.update({e:f})\n",
    "                    edge_feat.append(\n",
    "                        composition_to_feature(composit_dict = edge_comp, \n",
    "                                               feature_type = feat_type, \n",
    "                                               by_fraction = True,\n",
    "                                               norm = True)\n",
    "                    )\n",
    "        self.edge_index = np.array(edge_index, dtype=int).T\n",
    "        self.edge_feat = np.vstack(edge_feat, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EOS_LABEL = 999\n",
    "class SequenceData(ReactionData):\n",
    "    def __init__(self, \n",
    "                 data : Dict = {},\n",
    "                 feat_type : str = 'composit',\n",
    "                 target_comp : Dict = {},\n",
    "                 precursor_comps : List[Dict] = [],\n",
    "                 conditions : List[str] = [],\n",
    "                 condition_values : List[float] = [],\n",
    "                 max_length : int = 8,\n",
    "                 weights : float = None,\n",
    "                 *args, **kwargs):\n",
    "        super().__init__(data = data,\n",
    "                         feat_type = feat_type,\n",
    "                         target_comp = target_comp,\n",
    "                         precursor_comps = precursor_comps,\n",
    "                         conditions = conditions,\n",
    "                         condition_values = condition_values,\n",
    "                         weights = weights,\n",
    "                         *args, **kwargs)\n",
    "        \n",
    "        self._feature_attrs.pop(self._feature_attrs.index('metal_feat'))\n",
    "        delattr(self, 'metal_feat')\n",
    "        self.n = max_length\n",
    "\n",
    "        # labels & precursor feat\n",
    "        pad = composition_to_feature({}, feature_type=feat_type)\n",
    "        if hasattr(self, 'precursor_feat'):\n",
    "            self.m = self.labels.shape[0]\n",
    "            self.precursor_feat = np.vstack([\n",
    "                pad.reshape(1,-1), self.precursor_feat, *[pad] * max_length\n",
    "            ])[:max_length]\n",
    "            self.labels = np.hstack([\n",
    "                self.labels.reshape(-1), [EOS_LABEL] * max_length\n",
    "            ])[:max_length].astype(int)\n",
    "        else:\n",
    "            self._feature_attrs.append('precursor_feat')\n",
    "            self.precursor_feat = pad.reshape(1,-1)\n",
    "        self.to_torch()\n",
    "\n",
    "    def shuffle(self):\n",
    "        if not hasattr(self, 'm'): \n",
    "            return\n",
    "        j = np.random.permutation(self.m)\n",
    "        i1 = np.arange(self.n)\n",
    "        i2 = np.arange(self.n)\n",
    "        i1[:self.m] = j\n",
    "        i2[1:self.m+1] = j+1\n",
    "        return self.precursor_feat[i2], self.labels[i1]\n",
    "\n",
    "seq_data = SequenceData(data = data,\n",
    "                        feat_type = 'composit',\n",
    "                        target_comp = data['target_comp'],\n",
    "                        precursor_comps = data['precursor_comp'],\n",
    "#                        conditions = ['heat_temp'],\n",
    "#                        condition_values = [data['target_comp']['heat_temp']['median']],\n",
    "                        )\n",
    "seq_data.precursor_feat.shape, seq_data.target_feat.shape, seq_data.labels\n",
    "seq_data.shuffle()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import composit_parser\n",
    "check = {}\n",
    "for i in range(10000):\n",
    "    comp, lbl = seq_data.shuffle()\n",
    "    for j, (c, l) in enumerate(zip(comp[1:].cpu().numpy(), lbl.cpu().numpy())):\n",
    "        if l == 999: break\n",
    "        pstr = composit_parser({ActiveElements[k]: c[k] for k in np.where(c)[0]})\n",
    "        if pstr not in check.keys():\n",
    "            check[pstr] = {'order':[0]*5}\n",
    "        if l not in check[pstr].keys():\n",
    "            check[pstr][l] = 0\n",
    "        check[pstr][l] += 1\n",
    "        check[pstr]['order'][j] += 1\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.zeros(5)\n",
    "x = np.array([\n",
    "    [1,1,1,1,1],\n",
    "    [2,2,2,2,2],\n",
    "    [3,3,3,3,3],\n",
    "    [4,4,4,4,4],\n",
    "    [5,5,5,5,5],\n",
    "])\n",
    "np.vstack([\n",
    "    p, x, *[p] * 5\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['precursor_comp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "import torch, os\n",
    "from src.data import ReactionGraphDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from scipy.stats import gaussian_kde\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#['cgcnn','elemnet','magpie','magpie_sc','mat2vec','matscholar','megnet16','oliynyk','oliynyk_sc']\n",
    "ds = ReactionGraphDataset(feat_type='composit')\n",
    "ds.from_file('../data/screened_conditional_reaction.pkl.gz', \n",
    "             heat_temp_key=('heat_temp', 'median'))\n",
    "#ds.from_file('../data/surxn.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.num_meta_feat + ds.has_temp_info + ds.has_time_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1900\n",
    "for l,m in zip(ds[i].label, ds[i].label_mask):\n",
    "    print(l[m], m.sum())\n",
    "ds[i].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat, info = ds.cfn(ds[80:90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat['condition_feat'].shape, feat['x'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### collate_fnc design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cfn(self, dataset):\n",
    "    info = []\n",
    "    rxn_id = []\n",
    "    meta_feat = []\n",
    "    edge_feat = []\n",
    "    edge_index = []\n",
    "    condition_feat = []\n",
    "    prec_feat = []\n",
    "    label = []\n",
    "    label_mask = []\n",
    "    weight = []\n",
    "    n = 0\n",
    "    for i, data in enumerate(dataset):\n",
    "        info.append(data.to_dict())\n",
    "        rxn_id.append([i] * data.n)\n",
    "        meta_feat.append(data.meta_feat)\n",
    "        edge_feat.append(data.edge_feat)\n",
    "        edge_index.append(data.edge_index + n)\n",
    "        n += data.n\n",
    "    rxn_id = np.hstack(rxn_id).astype(int)\n",
    "    meta_feat = torch.vstack(meta_feat).float()\n",
    "    edge_feat = torch.vstack(edge_feat).float()\n",
    "    edge_index = torch.vstack(edge_index).long()\n",
    "\n",
    "    if self.has_temp_info or self.has_time_info:\n",
    "        for data in dataset:\n",
    "            condition_feat.append(data.condition_feat.repeat(data.n, 1))\n",
    "        condition_feat = torch.vstack(condition_feat).float()\n",
    "\n",
    "    if self._train:\n",
    "        for data in dataset:\n",
    "            prec_feat.append(data.precursor_feat)\n",
    "            label.append(data.label)\n",
    "            label_mask.append(data.label_mask)\n",
    "            weight.append(data.weight.repeat(data.label.shape))\n",
    "        prec_feat = torch.vstack(prec_feat)\n",
    "        label = torch.vstack(label)\n",
    "        label_mask = torch.vstack(label_mask)\n",
    "        weight = torch.vstack(weight)\n",
    "\n",
    "    return {\n",
    "        'rxn_id' : rxn_id,\n",
    "        'x' : meta_feat,\n",
    "        'edge_attr' : edge_feat,\n",
    "        'edge_index' : edge_index,\n",
    "        'condition_feat' : condition_feat,\n",
    "        'prec_feat' : prec_feat,\n",
    "        'label' : label,\n",
    "        'label_mask' : label_mask,\n",
    "        'weight' : weight,\n",
    "    }, info\n",
    "\n",
    "feat, info = cfn(ds, ds[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = [d.to_dict() for d in ds]\n",
    "info[88], info[89]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat = {}\n",
    "for d in info:\n",
    "    id = d['id_urxn']\n",
    "    if id not in stat:\n",
    "        stat[id] = {'count':d['count'], 'ids':[]}\n",
    "    stat[id]['ids'].append(d['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique([len(v['ids']) - v['count'] for k, v in stat.items()], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in stat.items():\n",
    "    if v['count'] - len(v['ids']) > 0:\n",
    "        print(v['count'], len(v['ids']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sequential dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 완성 후 삭제함\n",
    "cfn = ds.cfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat, info = cfn(ds, ds[:48])\n",
    "#feat, info = ds.cfn(ds[:48])\n",
    "for k,v in feat.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embd = torch.stack([torch.ones(10) * i for i in range(445)])\n",
    "embd[feat['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = torch.nn.Embedding(445, 10, padding_idx=444)\n",
    "#embed.to('cuda')\n",
    "#embed = embed.from_pretrained(embd)\n",
    "embed.padding_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for feat_type in ['composit','cgcnn','elemnet','magpie','magpie_sc','mat2vec','matscholar','megnet16','oliynyk','oliynyk_sc']:\n",
    "    ds = ReactionDataset(feat_type=feat_type)\n",
    "    ds.from_file('../data/screened_conditional_reaction.pkl.gz')\n",
    "    feat, info = ds.cfn(ds)\n",
    "    n = len(ds)\n",
    "    mask = np.hstack([np.zeros((n, 1), dtype=bool), (feat['label'] != EOS_LABEL)[..., :-1].cpu().numpy()]).reshape(-1)\n",
    "    inps = feat['inp'].numpy().reshape(n * 8, -1)[mask].T\n",
    "    conds = feat['condition'].numpy().reshape(n * 8, -1)[mask].T\n",
    "    f, ax = plt.subplots(1, 1, figsize=(25, 4))\n",
    "    f.suptitle(feat_type)\n",
    "    for i, (inp, cond) in enumerate(zip(inps, conds)):\n",
    "        ic = np.hstack([inp, cond])\n",
    "        if ic.max() - ic.min() < 1e-2: continue\n",
    "        y = np.linspace(ic.min(), ic.max(), 100)\n",
    "        for j, (v, lbl) in enumerate(zip([inp, cond], ['precursor','target'])):\n",
    "            x1 = gaussian_kde(v)(y)\n",
    "            x0 = np.ones_like(y) * i\n",
    "            if i == 0:\n",
    "                ax.fill_betweenx(y, x0, x1 / x1.max() + i, color=plt.cm.tab10(j), alpha=0.3, label=lbl)\n",
    "                ax.plot([i, i+1], [v.mean(), v.mean()], ls='--', color=plt.cm.tab10(j), lw=2, label='Avg.')\n",
    "            else:\n",
    "                ax.fill_betweenx(y, x0, x1 / x1.max() + i, color=plt.cm.tab10(j), alpha=0.3)\n",
    "                ax.plot([i, i+1], [v.mean(), v.mean()], ls='--', color=plt.cm.tab10(j), lw=2)\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.set_xlim([-1, i+2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conditions - Temp. & time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ReactionDataset(feat_type='composit')\n",
    "ds.from_file('../data/screened_conditional_reaction.pkl.gz', heat_temp_key=['heat_temp','median'])\n",
    "temp_median = ds.cfn(ds)[0]['condition'][:, 0, -1]\n",
    "ds.from_file('../data/screened_conditional_reaction.pkl.gz', heat_temp_key=['heat_time','median'])\n",
    "time_median = ds.cfn(ds)[0]['condition'][:, 0, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(4, 1, figsize=(10, 8))\n",
    "for i, (val, fnc) in enumerate([(temp_median, lambda x: x / 1000 - 1), \n",
    "                                (time_median, lambda x: np.log10(x) - 1)]):\n",
    "    for j, v in enumerate([val.numpy(), fnc(val.numpy())]):\n",
    "        vmax, vmin = v.max(), v.min()\n",
    "        y = np.linspace(vmin - (vmax - vmin) * 0.1, vmax + (vmax - vmin) * 0.1, 100)\n",
    "        x1 = gaussian_kde(v)(y)\n",
    "        x0 = np.zeros_like(y) \n",
    "        axs[i * 2 + j].fill_between(y, x0, x1 / x1.max())\n",
    "        axs[i * 2 + j].plot([vmax, vmax], [0, 1])\n",
    "        axs[i * 2 + j].plot([vmin, vmin], [0, 1])\n",
    "        axs[i * 2 + j].set_ylim([0, 1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_median.min(), temp_mean.min(), time_median.min(), time_mean.min(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model compatibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, torch, os\n",
    "sys.path.append('..')\n",
    "from src.networks import BaseNetwork, TransformerDecoderBlock\n",
    "from src.data import ReactionDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ReactionDataset()\n",
    "train_ds.from_file('../data/screened_conditional_reaction.pkl.gz', heat_temp_key=('heat_temp','median'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### funcionalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdb = TransformerDecoderBlock(72)\n",
    "tdb.device, tdb._dummy, tdb.state_dict()['target_embed_layer.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdb.to('cuda')\n",
    "#tdb._dummy = torch.tensor([0])\n",
    "#tdb._dummy.to('cuda')\n",
    "#tdb.positional_encoding.pe = tdb.positional_encoding.pe.to('cuda')\n",
    "tdb.positional_encoding.pe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### positional encoding test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 100\n",
    "hidden_dim = 64\n",
    "\n",
    "pe = torch.zeros(1, max_len, hidden_dim)\n",
    "position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "div_term = torch.exp(torch.arange(0, hidden_dim, 2).float() * (-np.log(10000.0) / hidden_dim))\n",
    "pe[..., 0::2] = torch.sin(position * div_term)\n",
    "pe[..., 1::2] = torch.cos(position * div_term)\n",
    "for i in range(9):\n",
    "    plt.plot(pe[0,i,::2], color=plt.cm.viridis(i/8))\n",
    "    plt.plot(pe[0,i,1::2], ls='--', color=plt.cm.viridis(i/8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pec = PositionalEncoding(hidden_dim)\n",
    "print(np.max(np.abs(pec(100)[0].numpy() - pe.numpy()[0]).reshape(-1)))\n",
    "plt.hist(np.abs(pec(100)[0].numpy() - pe.numpy()[0]).reshape(-1))\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(pec(100)[0].numpy() - pe.numpy()[0], cmap='RdBu', vmin=-1e-6, vmax=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat, info = train_ds.cfn(train_ds[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "for d in train_ds[:10]:\n",
    "    test.append(d.precursor_feat)\n",
    "\n",
    "torch.concat(test).shape\n",
    "#d.precursor_feat.shape\n",
    "#d.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x + out[1]\n",
    "y[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- forwarding test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = TransformerDecoderBlock(NUM_LABEL, 98)\n",
    "out = Model(feat['labels'], feat['conditions'])\n",
    "#out[1]\n",
    "#out[1].shape\n",
    "#\n",
    "#x = torch.ones(10, 8, 32) * torch.arange(0, 10, 1).view(-1,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- generation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = feat['conditions']\n",
    "\n",
    "output_seq = torch.ones(context.shape[0], 1).long() * SOS_LABEL\n",
    "for i in range(5):\n",
    "    o = Model(output_seq, feat['conditions'])\n",
    "    output_seq = torch.hstack([output_seq, o.argmax(-1)[:, -1:]])\n",
    "output_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- done in sequence.ipynb file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import ReactionGraphDataset, ReactionDataset\n",
    "from src.networks import GraphCVAE, CVAE, GraphConvolutionBlock, GraphAttentionBlock\n",
    "from src.trainer import VAETrainer, BaseTrainer\n",
    "\n",
    "GDS = ReactionGraphDataset(feat_type='cgcnn')\n",
    "GDS.from_file('../data/screened_conditional_reaction.pkl.gz', \n",
    "              heat_temp_key=('heat_temp','median'))\n",
    "\n",
    "# DS = ReactionDataset()\n",
    "# DS.from_file('../data/screened_conditional_reaction.pkl.gz', \n",
    "#              heat_temp_key=('heat_temp','median'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0 /   0.0875   0.0072   0.0053 /    31.6707    26.3887\n",
      "   1 /   0.0081   0.0085   0.0049 /    37.5922    28.6300\n",
      "   2 /   0.0024   0.0013   0.0012 /    37.9308    28.7833\n",
      "   3 /   0.0019   0.0011   0.0009 /    37.5561    29.9825\n",
      "   4 /   0.0009   0.0007   0.0007 /    38.3305    29.5627\n",
      "   5 /   0.0006   0.0008   0.0004 /    35.4856    27.1718\n",
      "   6 /   0.0004   0.0003   0.0003 /    37.0032    28.4475\n",
      "   7 /   0.0017   1.4812   0.5392 / 13628.4580  5052.3838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhyang/anaconda3/envs/isyn2/lib/python3.9/site-packages/numpy/core/_methods.py:118: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   8 /   0.0550 78508.1088 14256229376.0144 /        inf        inf\n",
      "   9 /   0.0308   0.0658 36437.9225 / 143999912706324484179684266868736.0000        inf\n",
      "  10 /   0.0252   0.0616 298211.9593 / 11139675244031772955735713478868992.0000        inf\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 77\u001b[0m\n\u001b[1;32m     68\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# for j, batch in enumerate(train_dl):\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m#     _loss, _output = tr._eval_batch(batch, True, 1e-4)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;66;03m#     tr.opt.step()\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;66;03m# if _loss.isnan().item(): break\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     valid_loss, valid_output \u001b[38;5;241m=\u001b[39m tr\u001b[38;5;241m.\u001b[39mtest(valid_dl)\n\u001b[1;32m     79\u001b[0m     test_loss, test_output \u001b[38;5;241m=\u001b[39m tr\u001b[38;5;241m.\u001b[39mtest(test_dl)\n",
      "File \u001b[0;32m~/WORKSPACES/CODES/inorganic_synthesis/notebooks/../src/trainer.py:21\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self, dataloader, *args, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m---> 21\u001b[0m     loss, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_eval_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     24\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Cell \u001b[0;32mIn[97], line 43\u001b[0m, in \u001b[0;36mTestTR._eval_batch\u001b[0;34m(self, batch, compute_loss, beta, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m _feat, _ \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# x = _feat['condition'].to('cuda')\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# edge_attr = _feat['edge_attr'].to('cuda')\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# edge_index = _feat['edge_index'].to('cuda')\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# pred = self.model(x=x, edge_attr=edge_attr, edge_index=edge_index)\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# output = [pred.detach()]\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m pred, kld, l, z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_feat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m mu, log_var \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mchunk(l\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu(), \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# output = [pred.detach(), kld.detach(), mu, log_var.exp(), z.detach()]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/isyn2/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/isyn2/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/WORKSPACES/CODES/inorganic_synthesis/notebooks/../src/networks.py:649\u001b[0m, in \u001b[0;36mGraphCVAE.forward\u001b[0;34m(self, x, edge_index, edge_attr, condition, *args, **kwargs)\u001b[0m\n\u001b[1;32m    647\u001b[0m l \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x \u001b[38;5;241m=\u001b[39m x, edge_index \u001b[38;5;241m=\u001b[39m edge_index, edge_attr \u001b[38;5;241m=\u001b[39m edge_attr)\n\u001b[1;32m    648\u001b[0m z, kld \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreparameterization(l)\n\u001b[0;32m--> 649\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y, kld, l, z\n",
      "File \u001b[0;32m~/anaconda3/envs/isyn2/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/isyn2/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/WORKSPACES/CODES/inorganic_synthesis/notebooks/../src/networks.py:242\u001b[0m, in \u001b[0;36mGraphConvolutionBlock.forward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m    240\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_embed_layer(x)\n\u001b[1;32m    241\u001b[0m edge_attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_embed_layer(edge_attr)\n\u001b[0;32m--> 242\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer(h)\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/envs/isyn2/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/isyn2/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/torch_geometric.nn.sequential_52d1e7_gamy54z1.py:37\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m     35\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_4(x, edge_index, edge_attr)\n\u001b[1;32m     36\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_5(x)\n\u001b[0;32m---> 37\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule_6\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_7(x)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/isyn2/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/isyn2/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/isyn2/lib/python3.9/site-packages/torch_geometric/nn/conv/cg_conv.py:88\u001b[0m, in \u001b[0;36mCGConv.forward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m     85\u001b[0m     x \u001b[38;5;241m=\u001b[39m (x, x)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: PairTensor, edge_attr: OptTensor)\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m out \u001b[38;5;241m=\u001b[39m out \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn(out)\n\u001b[1;32m     90\u001b[0m out \u001b[38;5;241m=\u001b[39m out \u001b[38;5;241m+\u001b[39m x[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/isyn2/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py:538\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m decomp_args:\n\u001b[1;32m    536\u001b[0m         kwargs[arg] \u001b[38;5;241m=\u001b[39m decomp_kwargs[arg][i]\n\u001b[0;32m--> 538\u001b[0m coll_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_user_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmutable_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    541\u001b[0m msg_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minspector\u001b[38;5;241m.\u001b[39mcollect_param_data(\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m, coll_dict)\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_forward_pre_hooks\u001b[38;5;241m.\u001b[39mvalues():\n",
      "File \u001b[0;32m~/anaconda3/envs/isyn2/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py:421\u001b[0m, in \u001b[0;36mMessagePassing._collect\u001b[0;34m(self, args, edge_index, size, kwargs)\u001b[0m\n\u001b[1;32m    419\u001b[0m out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madj_t\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    420\u001b[0m out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m edge_index\n\u001b[0;32m--> 421\u001b[0m out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index_i\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    422\u001b[0m out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index_j\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m edge_index[j]\n\u001b[1;32m    423\u001b[0m out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mptr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "years = np.array([d.year for d in GDS])\n",
    "train_idx = np.where(years < 2017)[0]\n",
    "valid_idx = np.where((years > 2016) & (years < 2019))[0]\n",
    "test_idx = np.where(years > 2018)[0]\n",
    "\n",
    "train_dl = DataLoader(GDS, batch_size=256, sampler=SubsetRandomSampler(train_idx), collate_fn=GDS.cfn)\n",
    "valid_dl = DataLoader(GDS, batch_size=2048, sampler=valid_idx, collate_fn=GDS.cfn)\n",
    "test_dl = DataLoader(GDS, batch_size=2048, sampler=test_idx, collate_fn=GDS.cfn)\n",
    "\n",
    "model = GraphCVAE(\n",
    "    input_dim=GDS.num_precursor_feat, latent_dim=16, \n",
    "    condition_dim=GDS.num_meta_feat + GDS.has_temp_info + GDS.has_time_info, \n",
    "    edge_dim=GDS.num_edge_feat, output_dim=GDS.NUM_LABEL + 5, graph='conv',\n",
    "    encoder_hidden_dim=128, encoder_hidden_layers=4,\n",
    "    decoder_hidden_dim=128, decoder_hidden_layers=4,\n",
    "    batch_norm=True, dropout=0,\n",
    ")\n",
    "\n",
    "class TestTR(BaseTrainer):\n",
    "    def __init__(self, model, lr, device='cuda', crit=torch.nn.CrossEntropyLoss(reduction='none')):\n",
    "        super().__init__(model, lr, device, crit,\n",
    "                         feat_keys=['label','label_mask','rxn_id','weight'],\n",
    "                        #  output_keys=['pred','kld','mu','log_var','z']\n",
    "                        output_keys=['n_label','pred','kld','mu','log_var','z']\n",
    "#                         output_keys=['pred',]\n",
    "                         )\n",
    "    \n",
    "    def _eval_batch(self, batch, compute_loss=True, beta=0.01, *args, **kwargs):\n",
    "        _feat, _ = batch\n",
    "        # x = _feat['condition'].to('cuda')\n",
    "        # edge_attr = _feat['edge_attr'].to('cuda')\n",
    "        # edge_index = _feat['edge_index'].to('cuda')\n",
    "        # pred = self.model(x=x, edge_attr=edge_attr, edge_index=edge_index)\n",
    "        # output = [pred.detach()]\n",
    "\n",
    "        pred, kld, l, z = self.model(**{k:v.to('cuda') for k,v in _feat.items() if isinstance(v, torch.Tensor)})\n",
    "        mu, log_var = torch.chunk(l.detach().cpu(), 2, -1)\n",
    "        # output = [pred.detach(), kld.detach(), mu, log_var.exp(), z.detach()]\n",
    "        pred_num = pred[:, :5]\n",
    "        pred_vec = pred[:, 5:]\n",
    "        output = [pred_num.detach(), pred_vec.detach(), kld.detach(), mu, log_var.exp(), z.detach()]\n",
    "        if compute_loss:\n",
    "            label = _feat['label'].to('cuda')\n",
    "            num_label = _feat['label'].sum(1).long().to('cuda')\n",
    "            pred_vec * _feat['label_mask'].to('cuda') * num_label\n",
    "                \n",
    "            loss_num = self.crit(pred_num, num_label)\n",
    "            return loss_num.mean(), output\n",
    "            # alpha = (label[_feat['label_mask']] - 0.25).abs()\n",
    "            # ce_loss = (self.crit(pred, feat['label']) * (feat['label_mask'] + 1e-4)).mean()\n",
    "            # bce_loss = self.crit(pred, label)[_feat['label_mask']]\n",
    "            # focal_loss = alpha * (1 - torch.exp(-bce_loss)) ** 2 * bce_loss\n",
    "            # mse = torch.mean(torch.sum(torch.square(feat['x'] - pvec), -1))\n",
    "            # loss = focal_loss + beta * kld.sum()\n",
    "            # return loss.mean(), output\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "tr = TestTR(model, lr=1e-3)\n",
    "best_valid_loss = 1e5\n",
    "count = 0\n",
    "for i in range(100):\n",
    "    # for j, batch in enumerate(train_dl):\n",
    "    #     _loss, _output = tr._eval_batch(batch, True, 1e-4)\n",
    "    #     if _loss.isnan().item(): break\n",
    "    #     tr.opt.zero_grad()\n",
    "    #     _loss.backward()\n",
    "    #     tr.opt.step()\n",
    "    # if _loss.isnan().item(): break\n",
    "    train_loss = tr.train(train_dl)\n",
    "    valid_loss, valid_output = tr.test(valid_dl)\n",
    "    test_loss, test_output = tr.test(test_dl)\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_output = valid_output\n",
    "        best_test_output = test_output\n",
    "        best_valid_loss = valid_loss\n",
    "        count = 0\n",
    "    if count > 25:\n",
    "        break\n",
    "    print('{:4d} / {:8.4f} {:8.4f} {:8.4f} / {:10.4f} {:10.4f}'.format(\n",
    "        i, train_loss, valid_loss, test_loss, np.vstack(valid_output['kld']).mean(), np.vstack(test_output['kld']).mean()))\n",
    "    # print('{:4d} / {:12.8f} {:12.8f} {:12.8f}'.format(i, train_loss, valid_loss, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.trainer import VAETrainer\n",
    "\n",
    "class VAEMaskedClassTrainer(VAETrainer):\n",
    "    def __init__(self, model, lr, device='cuda', crit=torch.nn.BCEWithLogitsLoss(reduction='none')):\n",
    "        super().__init__(model, lr, device)\n",
    "    \n",
    "    def _eval_batch(self, batch, compute_loss=True, beta=0.1):\n",
    "        feat, _ = batch\n",
    "        pred, kld, l, z = self.model(**feat)\n",
    "        mu, log_var = torch.chunk(l.detach().cpu(), 2, -1)\n",
    "        output = [pred.detach().cpu().numpy(), kld.detach().cpu().numpy(), mu.numpy(), log_var.exp().numpy(), z.detach().cpu().numpy()]\n",
    "        if compute_loss:\n",
    "            bce_loss = self.crit(pred, feat['label'])[feat['label_mask']].mean()\n",
    "            loss = bce_loss + beta * kld.sum()\n",
    "            return loss, output\n",
    "        else:\n",
    "            return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit1 = torch.nn.BCEWithLogitsLoss(reduction='none')\n",
    "crit2 = torch.nn.BCELoss(reduction='none')\n",
    "\n",
    "feat, info = next(iter(valid_dl))\n",
    "\n",
    "y = feat['label'].float()\n",
    "x = torch.zeros_like(y)\n",
    "loss = crit1(x, y)[feat['label_mask']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.shape, 8444 * 94, crit1(x, y).view(-1)[feat['label_mask'].view(-1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "years = np.array([d.year for d in DS])\n",
    "DS.to('cuda')\n",
    "train_idx = np.where(years < 2017)[0]\n",
    "valid_idx = np.where((years > 2016) & (years < 2019))[0]\n",
    "test_idx = np.where(years > 2018)[0]\n",
    "\n",
    "train_dl = DataLoader(DS, batch_size=256, sampler=SubsetRandomSampler(train_idx), collate_fn=DS.cfn)\n",
    "valid_dl = DataLoader(DS, batch_size=2048, sampler=valid_idx, collate_fn=DS.cfn)\n",
    "test_dl = DataLoader(DS, batch_size=2048, sampler=valid_idx, collate_fn=DS.cfn)\n",
    "\n",
    "model = DNNCVAE(DS.num_ligand_feat, 16, DS.num_target_feat + DS.num_metal_feat,\n",
    "                encoder_hidden_dim=128, encoder_hidden_layers=4,\n",
    "                decoder_hidden_dim=128, decoder_hidden_layers=4)\n",
    "\n",
    "tr = VAETrainer(model, 1e-5)\n",
    "\n",
    "path = '/home/jhyang/WORKSPACES/MODELS/isyn/VAE/dnn_16_cgcnn_test'\n",
    "os.makedirs(path, exist_ok=True)\n",
    "writer = SummaryWriter(path)\n",
    "for i in range(50):\n",
    "    train_loss = tr.train(train_dl)\n",
    "    writer.add_scalar('Loss/Train', train_loss, i+1)\n",
    "    valid_loss, valid_output = tr.test(valid_dl)\n",
    "    test_loss, test_output = tr.test(test_dl)\n",
    "\n",
    "    writer.add_scalar('Loss/Valid', valid_loss, i+1)\n",
    "    writer.add_scalar('Loss/Test', test_loss, i+1)\n",
    "    writer.add_scalar('KLD/Valid', valid_output['kld'], i+1)\n",
    "    writer.add_scalar('KLD/Test', test_output['kld'], i+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.feature import feature_to_composit, ligand_label\n",
    "def feature_to_ligand_index(feat_vec, tol=0.5):\n",
    "    comps = feature_to_composit(feat_vec, tol)\n",
    "    out = []\n",
    "    for comp in comps:\n",
    "        eles = '-'.join(comp.keys())\n",
    "        i = ligand_label.get(eles)\n",
    "        out.append(-1 if i is None else i)\n",
    "    return out\n",
    "\n",
    "inp = feature_to_ligand_index(valid_output['input'])\n",
    "prd = feature_to_ligand_index(valid_output['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _feature_to_composit(feat_vec, tol=0.5, to_string=False, to_idx=False):\n",
    "    n_feat = feat_vec.shape[-1]\n",
    "    if n_feat not in [97, 87, 12]:\n",
    "        raise TypeError(f'feature type is not supported', composit_fnc)\n",
    "    if n_feat == 97: # active_composit\n",
    "        ref = ActiveElements\n",
    "    elif n_feat == 87: # metal_composit\n",
    "        ref = ['None'] + MetalElements\n",
    "    elif n_feat == 12: # ligand_composit\n",
    "        ref = ['Metal'] + LigandElements\n",
    "    mask = feat_vec > tol\n",
    "    out = [tuple([ref[i] for i in np.where(vec)[0]]) for vec in mask]\n",
    "    if to_string or to_idx:\n",
    "        out = ['-'.join(o) for o in out]\n",
    "    if to_idx:\n",
    "        out = [ligand_label[o] if o in ligand_label.keys() else -1 for o in out]\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(inp, prd, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'.'.join(ligand_label.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.data import ReactionDataset\n",
    "from src.feature import init_info\n",
    "\n",
    "init_info(0)\n",
    "rd = ReactionDataset(precursor_feat_type='active_composit')\n",
    "rd.from_file()\n",
    "len(rd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd.to('cpu')\n",
    "feat, info = rd.cfn(rd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.unique(feat['label'].numpy(), return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isyn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
